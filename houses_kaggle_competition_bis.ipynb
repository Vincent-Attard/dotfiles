{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vincent-Attard/dotfiles/blob/master/houses_kaggle_competition_bis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK62GN2qBILl"
      },
      "source": [
        "# Houses Kaggle Competition (revisited with Deep Learning üî•) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXken5c8BILp"
      },
      "source": [
        "[<img src='https://github.com/lewagon/data-images/blob/master/ML/kaggle-batch-challenge.png?raw=true' width=600>](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
        "\n",
        "‚öôÔ∏è Let's re-use our previous **pipeline** built in the module **`05-07-Ensemble-Methods`** and try to improve our final predictions with a Neural Network!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgMzNWzBBILp"
      },
      "source": [
        "## (0) Libraries and imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gfuYAj7CBILq"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# DATA MANIPULATION\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "import numpy as np\n",
        "\n",
        "# DATA VISUALISATION\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# VIEWING OPTIONS IN THE NOTEBOOK\n",
        "from sklearn import set_config; set_config(display='diagram')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u484ZgosBILr"
      },
      "source": [
        "## (1) üöÄ Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFLWLVYWBILr"
      },
      "source": [
        "### (1.1) Load the datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSCXNhRTBILs"
      },
      "source": [
        "üíæ Let's load our **training dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tONq9rhDBILs"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/houses_train_raw.csv\")\n",
        "X = data.drop(columns='SalePrice')\n",
        "y = data['SalePrice']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "FthO6f1fBILt",
        "outputId": "29b9d343-b2d1-44bb-900f-6c16d7efc773"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities LotConfig LandSlope Neighborhood Condition1  \\\n",
              "0         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
              "1         Lvl    AllPub       FR2       Gtl      Veenker      Feedr   \n",
              "2         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
              "3         Lvl    AllPub    Corner       Gtl      Crawfor       Norm   \n",
              "4         Lvl    AllPub       FR2       Gtl      NoRidge       Norm   \n",
              "\n",
              "  Condition2 BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  \\\n",
              "0       Norm     1Fam     2Story            7            5       2003   \n",
              "1       Norm     1Fam     1Story            6            8       1976   \n",
              "2       Norm     1Fam     2Story            7            5       2001   \n",
              "3       Norm     1Fam     2Story            7            5       1915   \n",
              "4       Norm     1Fam     2Story            8            5       2000   \n",
              "\n",
              "   YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType  \\\n",
              "0          2003     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
              "1          1976     Gable  CompShg     MetalSd     MetalSd       None   \n",
              "2          2002     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
              "3          1970     Gable  CompShg     Wd Sdng     Wd Shng       None   \n",
              "4          2000     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
              "\n",
              "   MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure  \\\n",
              "0       196.0        Gd        TA      PConc       Gd       TA           No   \n",
              "1         0.0        TA        TA     CBlock       Gd       TA           Gd   \n",
              "2       162.0        Gd        TA      PConc       Gd       TA           Mn   \n",
              "3         0.0        TA        TA     BrkTil       TA       Gd           No   \n",
              "4       350.0        Gd        TA      PConc       Gd       TA           Av   \n",
              "\n",
              "  BsmtFinType1  BsmtFinSF1 BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n",
              "0          GLQ         706          Unf           0        150          856   \n",
              "1          ALQ         978          Unf           0        284         1262   \n",
              "2          GLQ         486          Unf           0        434          920   \n",
              "3          ALQ         216          Unf           0        540          756   \n",
              "4          GLQ         655          Unf           0        490         1145   \n",
              "\n",
              "  Heating HeatingQC CentralAir Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  \\\n",
              "0    GasA        Ex          Y      SBrkr       856       854             0   \n",
              "1    GasA        Ex          Y      SBrkr      1262         0             0   \n",
              "2    GasA        Ex          Y      SBrkr       920       866             0   \n",
              "3    GasA        Gd          Y      SBrkr       961       756             0   \n",
              "4    GasA        Ex          Y      SBrkr      1145      1053             0   \n",
              "\n",
              "   GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  \\\n",
              "0       1710             1             0         2         1             3   \n",
              "1       1262             0             1         2         0             3   \n",
              "2       1786             1             0         2         1             3   \n",
              "3       1717             1             0         1         0             3   \n",
              "4       2198             1             0         2         1             4   \n",
              "\n",
              "   KitchenAbvGr KitchenQual  TotRmsAbvGrd Functional  Fireplaces FireplaceQu  \\\n",
              "0             1          Gd             8        Typ           0         NaN   \n",
              "1             1          TA             6        Typ           1          TA   \n",
              "2             1          Gd             6        Typ           1          TA   \n",
              "3             1          Gd             7        Typ           1          Gd   \n",
              "4             1          Gd             9        Typ           1          TA   \n",
              "\n",
              "  GarageType  GarageYrBlt GarageFinish  GarageCars  GarageArea GarageQual  \\\n",
              "0     Attchd       2003.0          RFn           2         548         TA   \n",
              "1     Attchd       1976.0          RFn           2         460         TA   \n",
              "2     Attchd       2001.0          RFn           2         608         TA   \n",
              "3     Detchd       1998.0          Unf           3         642         TA   \n",
              "4     Attchd       2000.0          RFn           3         836         TA   \n",
              "\n",
              "  GarageCond PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
              "0         TA          Y           0           61              0          0   \n",
              "1         TA          Y         298            0              0          0   \n",
              "2         TA          Y           0           42              0          0   \n",
              "3         TA          Y           0           35            272          0   \n",
              "4         TA          Y         192           84              0          0   \n",
              "\n",
              "   ScreenPorch  PoolArea PoolQC Fence MiscFeature  MiscVal  MoSold  YrSold  \\\n",
              "0            0         0    NaN   NaN         NaN        0       2    2008   \n",
              "1            0         0    NaN   NaN         NaN        0       5    2007   \n",
              "2            0         0    NaN   NaN         NaN        0       9    2008   \n",
              "3            0         0    NaN   NaN         NaN        0       2    2006   \n",
              "4            0         0    NaN   NaN         NaN        0      12    2008   \n",
              "\n",
              "  SaleType SaleCondition  \n",
              "0       WD        Normal  \n",
              "1       WD        Normal  \n",
              "2       WD        Normal  \n",
              "3       WD       Abnorml  \n",
              "4       WD        Normal  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e0dd15e0-736c-4dff-baf1-2a05ae958ca0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition1</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>BldgType</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>RoofMatl</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtCond</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Heating</th>\n",
              "      <th>HeatingQC</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Functional</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FireplaceQu</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageQual</th>\n",
              "      <th>GarageCond</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>196.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>706</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>8</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>548</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Veenker</td>\n",
              "      <td>Feedr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>978</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>162.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>486</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>608</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Shng</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>BrkTil</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>216</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>3</td>\n",
              "      <td>642</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NoRidge</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>350.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Av</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>655</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>9</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>3</td>\n",
              "      <td>836</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0dd15e0-736c-4dff-baf1-2a05ae958ca0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e0dd15e0-736c-4dff-baf1-2a05ae958ca0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e0dd15e0-736c-4dff-baf1-2a05ae958ca0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkcEGlcoBILu",
        "outputId": "272d5d86-b464-4583-cd2d-f7972eea6bc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1460, 80), (1460,))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6_f1tjqBILu"
      },
      "source": [
        "üíæ Let's also load the **test set**\n",
        "\n",
        "‚ùóÔ∏è Remember ‚ùóÔ∏è You have access to `X_test` but only Kaggle has `y_test`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BrgGA2ojBILu"
      },
      "outputs": [],
      "source": [
        "X_test = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/houses_test_raw.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW9JmmMkBILv",
        "outputId": "508e4329-0f5a-47f2-d60e-4cc294b2a7a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1459, 80)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3cO32iCBILv"
      },
      "source": [
        "### (1.2) Train/Val Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg203RuzBILv"
      },
      "source": [
        "‚ùì **Holdout** ‚ùì \n",
        "\n",
        "As you are not allowed to use the test set (and you don't have access to `y_test` anyway), split your dataset into a training set and a validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "d2ovcKbbBILv"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = \\\n",
        "    train_test_split(X, y, test_size=0.30, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZioqtIVBILw"
      },
      "source": [
        "### (1.3) Import the preprocessor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXVpA3AhBILw"
      },
      "source": [
        "üéÅ You will find in `utils/preprocessor.py` the **`data-preprocessing pipeline`** that was built in our previous iteration.\n",
        "\n",
        "‚ùì Run the cell below, and make sure you understand what the pipeline does. Look at the code in `preprocessor.py` ‚ùì"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "QMf9rEYHBILw",
        "outputId": "e2a49785-4ed2-4d5a-adeb-3d0eca3b7d53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('columntransformer',\n",
              "                 ColumnTransformer(transformers=[('numerical_encoder',\n",
              "                                                  Pipeline(steps=[('knnimputer',\n",
              "                                                                   KNNImputer()),\n",
              "                                                                  ('minmaxscaler',\n",
              "                                                                   MinMaxScaler())]),\n",
              "                                                  ['1stFlrSF', '2ndFlrSF',\n",
              "                                                   '3SsnPorch', 'BedroomAbvGr',\n",
              "                                                   'BsmtFinSF1', 'BsmtFinSF2',\n",
              "                                                   'BsmtFullBath',\n",
              "                                                   'BsmtHalfBath', 'BsmtUnfSF',\n",
              "                                                   'EnclosedPorch',\n",
              "                                                   'Fireplaces', 'FullBath',\n",
              "                                                   'GarageArea', 'GarageCars...\n",
              "                                                   'CentralAir', 'Condition1',\n",
              "                                                   'Condition2', 'Exterior1st',\n",
              "                                                   'Exterior2nd', 'Foundation',\n",
              "                                                   'GarageType', 'Heating',\n",
              "                                                   'HouseStyle', 'LotConfig',\n",
              "                                                   'MSZoning', 'MasVnrType',\n",
              "                                                   'MiscFeature',\n",
              "                                                   'Neighborhood', 'RoofMatl',\n",
              "                                                   'RoofStyle', 'SaleCondition',\n",
              "                                                   'SaleType', 'Street',\n",
              "                                                   'Utilities'])])),\n",
              "                ('selectpercentile',\n",
              "                 SelectPercentile(percentile=75,\n",
              "                                  score_func=<function mutual_info_regression at 0x7f072f133710>))])"
            ],
            "text/html": [
              "<style>#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 {color: black;background-color: white;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 pre{padding: 0;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-toggleable {background-color: white;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-item {z-index: 1;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-parallel-item:only-child::after {width: 0;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-bb7e068b-00d2-42c9-ae81-e2d241ac43a1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;numerical_encoder&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;knnimputer&#x27;,\n",
              "                                                                   KNNImputer()),\n",
              "                                                                  (&#x27;minmaxscaler&#x27;,\n",
              "                                                                   MinMaxScaler())]),\n",
              "                                                  [&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;,\n",
              "                                                   &#x27;3SsnPorch&#x27;, &#x27;BedroomAbvGr&#x27;,\n",
              "                                                   &#x27;BsmtFinSF1&#x27;, &#x27;BsmtFinSF2&#x27;,\n",
              "                                                   &#x27;BsmtFullBath&#x27;,\n",
              "                                                   &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;,\n",
              "                                                   &#x27;EnclosedPorch&#x27;,\n",
              "                                                   &#x27;Fireplaces&#x27;, &#x27;FullBath&#x27;,\n",
              "                                                   &#x27;GarageArea&#x27;, &#x27;GarageCars...\n",
              "                                                   &#x27;CentralAir&#x27;, &#x27;Condition1&#x27;,\n",
              "                                                   &#x27;Condition2&#x27;, &#x27;Exterior1st&#x27;,\n",
              "                                                   &#x27;Exterior2nd&#x27;, &#x27;Foundation&#x27;,\n",
              "                                                   &#x27;GarageType&#x27;, &#x27;Heating&#x27;,\n",
              "                                                   &#x27;HouseStyle&#x27;, &#x27;LotConfig&#x27;,\n",
              "                                                   &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;,\n",
              "                                                   &#x27;MiscFeature&#x27;,\n",
              "                                                   &#x27;Neighborhood&#x27;, &#x27;RoofMatl&#x27;,\n",
              "                                                   &#x27;RoofStyle&#x27;, &#x27;SaleCondition&#x27;,\n",
              "                                                   &#x27;SaleType&#x27;, &#x27;Street&#x27;,\n",
              "                                                   &#x27;Utilities&#x27;])])),\n",
              "                (&#x27;selectpercentile&#x27;,\n",
              "                 SelectPercentile(percentile=75,\n",
              "                                  score_func=&lt;function mutual_info_regression at 0x7f072f133710&gt;))])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"05469954-ab33-42d2-b0bb-b269cbb21639\" type=\"checkbox\" ><label for=\"05469954-ab33-42d2-b0bb-b269cbb21639\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;numerical_encoder&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;knnimputer&#x27;,\n",
              "                                                                   KNNImputer()),\n",
              "                                                                  (&#x27;minmaxscaler&#x27;,\n",
              "                                                                   MinMaxScaler())]),\n",
              "                                                  [&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;,\n",
              "                                                   &#x27;3SsnPorch&#x27;, &#x27;BedroomAbvGr&#x27;,\n",
              "                                                   &#x27;BsmtFinSF1&#x27;, &#x27;BsmtFinSF2&#x27;,\n",
              "                                                   &#x27;BsmtFullBath&#x27;,\n",
              "                                                   &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;,\n",
              "                                                   &#x27;EnclosedPorch&#x27;,\n",
              "                                                   &#x27;Fireplaces&#x27;, &#x27;FullBath&#x27;,\n",
              "                                                   &#x27;GarageArea&#x27;, &#x27;GarageCars...\n",
              "                                                   &#x27;CentralAir&#x27;, &#x27;Condition1&#x27;,\n",
              "                                                   &#x27;Condition2&#x27;, &#x27;Exterior1st&#x27;,\n",
              "                                                   &#x27;Exterior2nd&#x27;, &#x27;Foundation&#x27;,\n",
              "                                                   &#x27;GarageType&#x27;, &#x27;Heating&#x27;,\n",
              "                                                   &#x27;HouseStyle&#x27;, &#x27;LotConfig&#x27;,\n",
              "                                                   &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;,\n",
              "                                                   &#x27;MiscFeature&#x27;,\n",
              "                                                   &#x27;Neighborhood&#x27;, &#x27;RoofMatl&#x27;,\n",
              "                                                   &#x27;RoofStyle&#x27;, &#x27;SaleCondition&#x27;,\n",
              "                                                   &#x27;SaleType&#x27;, &#x27;Street&#x27;,\n",
              "                                                   &#x27;Utilities&#x27;])])),\n",
              "                (&#x27;selectpercentile&#x27;,\n",
              "                 SelectPercentile(percentile=75,\n",
              "                                  score_func=&lt;function mutual_info_regression at 0x7f072f133710&gt;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"07d75690-4949-4461-b372-101f8ad6c245\" type=\"checkbox\" ><label for=\"07d75690-4949-4461-b372-101f8ad6c245\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;numerical_encoder&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;knnimputer&#x27;, KNNImputer()),\n",
              "                                                 (&#x27;minmaxscaler&#x27;,\n",
              "                                                  MinMaxScaler())]),\n",
              "                                 [&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;, &#x27;3SsnPorch&#x27;,\n",
              "                                  &#x27;BedroomAbvGr&#x27;, &#x27;BsmtFinSF1&#x27;, &#x27;BsmtFinSF2&#x27;,\n",
              "                                  &#x27;BsmtFullBath&#x27;, &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;,\n",
              "                                  &#x27;EnclosedPorch&#x27;, &#x27;Fireplaces&#x27;, &#x27;FullBath&#x27;,\n",
              "                                  &#x27;GarageArea&#x27;, &#x27;GarageCars&#x27;, &#x27;GarageYrBlt&#x27;,\n",
              "                                  &#x27;GrLivArea&#x27;, &#x27;HalfBath...\n",
              "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
              "                                                 (&#x27;onehotencoder&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
              "                                 [&#x27;Alley&#x27;, &#x27;BldgType&#x27;, &#x27;CentralAir&#x27;,\n",
              "                                  &#x27;Condition1&#x27;, &#x27;Condition2&#x27;, &#x27;Exterior1st&#x27;,\n",
              "                                  &#x27;Exterior2nd&#x27;, &#x27;Foundation&#x27;, &#x27;GarageType&#x27;,\n",
              "                                  &#x27;Heating&#x27;, &#x27;HouseStyle&#x27;, &#x27;LotConfig&#x27;,\n",
              "                                  &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;, &#x27;MiscFeature&#x27;,\n",
              "                                  &#x27;Neighborhood&#x27;, &#x27;RoofMatl&#x27;, &#x27;RoofStyle&#x27;,\n",
              "                                  &#x27;SaleCondition&#x27;, &#x27;SaleType&#x27;, &#x27;Street&#x27;,\n",
              "                                  &#x27;Utilities&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"cb669cbb-b890-4933-a798-e54f68fe6b57\" type=\"checkbox\" ><label for=\"cb669cbb-b890-4933-a798-e54f68fe6b57\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical_encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;1stFlrSF&#x27;, &#x27;2ndFlrSF&#x27;, &#x27;3SsnPorch&#x27;, &#x27;BedroomAbvGr&#x27;, &#x27;BsmtFinSF1&#x27;, &#x27;BsmtFinSF2&#x27;, &#x27;BsmtFullBath&#x27;, &#x27;BsmtHalfBath&#x27;, &#x27;BsmtUnfSF&#x27;, &#x27;EnclosedPorch&#x27;, &#x27;Fireplaces&#x27;, &#x27;FullBath&#x27;, &#x27;GarageArea&#x27;, &#x27;GarageCars&#x27;, &#x27;GarageYrBlt&#x27;, &#x27;GrLivArea&#x27;, &#x27;HalfBath&#x27;, &#x27;Id&#x27;, &#x27;KitchenAbvGr&#x27;, &#x27;LotArea&#x27;, &#x27;LotFrontage&#x27;, &#x27;LowQualFinSF&#x27;, &#x27;MSSubClass&#x27;, &#x27;MasVnrArea&#x27;, &#x27;MiscVal&#x27;, &#x27;MoSold&#x27;, &#x27;OpenPorchSF&#x27;, &#x27;OverallCond&#x27;, &#x27;OverallQual&#x27;, &#x27;PoolArea&#x27;, &#x27;ScreenPorch&#x27;, &#x27;TotRmsAbvGrd&#x27;, &#x27;TotalBsmtSF&#x27;, &#x27;WoodDeckSF&#x27;, &#x27;YearBuilt&#x27;, &#x27;YearRemodAdd&#x27;, &#x27;YrSold&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"66f6b527-a34f-4f3e-accb-0d36f54afe68\" type=\"checkbox\" ><label for=\"66f6b527-a34f-4f3e-accb-0d36f54afe68\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNNImputer</label><div class=\"sk-toggleable__content\"><pre>KNNImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"c60ed547-ca0c-471b-8f92-718f41fcb37b\" type=\"checkbox\" ><label for=\"c60ed547-ca0c-471b-8f92-718f41fcb37b\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"4ad872fb-38dc-4e2c-864e-84a06cd01814\" type=\"checkbox\" ><label for=\"4ad872fb-38dc-4e2c-864e-84a06cd01814\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ordinal_encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;BsmtCond&#x27;, &#x27;BsmtExposure&#x27;, &#x27;BsmtFinType1&#x27;, &#x27;BsmtFinType2&#x27;, &#x27;BsmtQual&#x27;, &#x27;Electrical&#x27;, &#x27;ExterCond&#x27;, &#x27;ExterQual&#x27;, &#x27;Fence&#x27;, &#x27;FireplaceQu&#x27;, &#x27;Functional&#x27;, &#x27;GarageCond&#x27;, &#x27;GarageFinish&#x27;, &#x27;GarageQual&#x27;, &#x27;HeatingQC&#x27;, &#x27;KitchenQual&#x27;, &#x27;LandContour&#x27;, &#x27;LandSlope&#x27;, &#x27;LotShape&#x27;, &#x27;PavedDrive&#x27;, &#x27;PoolQC&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"755c8f20-ffde-485f-abb6-03341af64c83\" type=\"checkbox\" ><label for=\"755c8f20-ffde-485f-abb6-03341af64c83\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=&#x27;missing&#x27;, strategy=&#x27;constant&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"00850bd3-2362-4998-bdbc-79fd00f94733\" type=\"checkbox\" ><label for=\"00850bd3-2362-4998-bdbc-79fd00f94733\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder(categories=[[&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;],\n",
              "                           [&#x27;missing&#x27;, &#x27;No&#x27;, &#x27;Mn&#x27;, &#x27;Av&#x27;, &#x27;Gd&#x27;],\n",
              "                           [&#x27;missing&#x27;, &#x27;Unf&#x27;, &#x27;LwQ&#x27;, &#x27;Rec&#x27;, &#x27;BLQ&#x27;, &#x27;ALQ&#x27;,\n",
              "                            &#x27;GLQ&#x27;],\n",
              "                           [&#x27;missing&#x27;, &#x27;Unf&#x27;, &#x27;LwQ&#x27;, &#x27;Rec&#x27;, &#x27;BLQ&#x27;, &#x27;ALQ&#x27;,\n",
              "                            &#x27;GLQ&#x27;],\n",
              "                           [&#x27;missing&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
              "                           [&#x27;missing&#x27;, &#x27;Mix&#x27;, &#x27;FuseP&#x27;, &#x27;FuseF&#x27;, &#x27;FuseA&#x27;,\n",
              "                            &#x27;SBrkr&#x27;],\n",
              "                           [&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
              "                           [&#x27;missing&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
              "                           [&#x27;missing&#x27;, &#x27;...\n",
              "                           [&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
              "                           [&#x27;missing&#x27;, &#x27;Unf&#x27;, &#x27;RFn&#x27;, &#x27;Fin&#x27;],\n",
              "                           [&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
              "                           [&#x27;missing&#x27;, &#x27;Po&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
              "                           [&#x27;missing&#x27;, &#x27;Fa&#x27;, &#x27;TA&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;],\n",
              "                           [&#x27;missing&#x27;, &#x27;Low&#x27;, &#x27;Bnk&#x27;, &#x27;HLS&#x27;, &#x27;Lvl&#x27;],\n",
              "                           [&#x27;missing&#x27;, &#x27;Sev&#x27;, &#x27;Mod&#x27;, &#x27;Gtl&#x27;],\n",
              "                           [&#x27;missing&#x27;, &#x27;IR3&#x27;, &#x27;IR2&#x27;, &#x27;IR1&#x27;, &#x27;Reg&#x27;],\n",
              "                           [&#x27;missing&#x27;, &#x27;N&#x27;, &#x27;P&#x27;, &#x27;Y&#x27;],\n",
              "                           [&#x27;missing&#x27;, &#x27;Fa&#x27;, &#x27;Gd&#x27;, &#x27;Ex&#x27;]],\n",
              "               handle_unknown=&#x27;use_encoded_value&#x27;, unknown_value=-1)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"1eefc61e-accf-4c23-a87a-be2f3a52e0bc\" type=\"checkbox\" ><label for=\"1eefc61e-accf-4c23-a87a-be2f3a52e0bc\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"c3a84e13-e60b-40f7-bed7-0e71b8011611\" type=\"checkbox\" ><label for=\"c3a84e13-e60b-40f7-bed7-0e71b8011611\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">nominal_encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Alley&#x27;, &#x27;BldgType&#x27;, &#x27;CentralAir&#x27;, &#x27;Condition1&#x27;, &#x27;Condition2&#x27;, &#x27;Exterior1st&#x27;, &#x27;Exterior2nd&#x27;, &#x27;Foundation&#x27;, &#x27;GarageType&#x27;, &#x27;Heating&#x27;, &#x27;HouseStyle&#x27;, &#x27;LotConfig&#x27;, &#x27;MSZoning&#x27;, &#x27;MasVnrType&#x27;, &#x27;MiscFeature&#x27;, &#x27;Neighborhood&#x27;, &#x27;RoofMatl&#x27;, &#x27;RoofStyle&#x27;, &#x27;SaleCondition&#x27;, &#x27;SaleType&#x27;, &#x27;Street&#x27;, &#x27;Utilities&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b94b2a4c-e495-41b6-aa14-2687c87484d5\" type=\"checkbox\" ><label for=\"b94b2a4c-e495-41b6-aa14-2687c87484d5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b58aae7b-3b92-444f-b6fc-090966b055fa\" type=\"checkbox\" ><label for=\"b58aae7b-3b92-444f-b6fc-090966b055fa\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"785c3c65-0895-4909-acec-783cc603fef5\" type=\"checkbox\" ><label for=\"785c3c65-0895-4909-acec-783cc603fef5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectPercentile</label><div class=\"sk-toggleable__content\"><pre>SelectPercentile(percentile=75,\n",
              "                 score_func=&lt;function mutual_info_regression at 0x7f072f133710&gt;)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from preprocessor import create_preproc\n",
        "\n",
        "preproc = create_preproc(X_train)\n",
        "preproc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAPbCwddBILw"
      },
      "source": [
        "‚ùì **Scaling your numerical features and encoding the categorical features** ‚ùì\n",
        "\n",
        "Apply these transformations to _both_ your training set and your validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPNqV04qBILw",
        "outputId": "5d5f673f-8421-489a-bb3a-f2e70a21eab4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.24982723, 0.52190171, 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [0.33068417, 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [0.18106427, 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       ...,\n",
              "       [0.34001382, 0.31196581, 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [0.42259848, 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [0.29751209, 0.34401709, 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "X_train_transformed = preproc.fit_transform(X_train, y_train)\n",
        "X_train_transformed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_transformed = preproc.transform(X_test)\n",
        "X_test_transformed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuKUvkkMERmu",
        "outputId": "52426673-7dca-4559-ebcf-25d279087840"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7536282 , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [0.21561852, 0.33119658, 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [0.22287491, 0.11965812, 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       ...,\n",
              "       [0.61472011, 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [0.42812716, 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [0.70145128, 0.        , 0.        , ..., 1.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiwJuOuLBILx"
      },
      "source": [
        "## (2) üîÆ Your predictions in Tensorflow/Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xIVSmqpBILx"
      },
      "source": [
        "üöÄ This is your first **regression** task with Keras! \n",
        "\n",
        "üí° Here a few tips to get started:\n",
        "- Kaggle's [rule](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview/evaluation) requires to minimize **`rmsle`** (Root Mean Square Log Error). \n",
        "    - As you can see, we can specify `msle` directly as a loss-function with Tensorflow.Keras!\n",
        "    - Just remember to take the square-root of your loss results to read your rmsle metric.\n",
        "    \n",
        "    \n",
        "üòÉ The best boosted-tree ***rmsle*** score to beat is around ***0.13***\n",
        "\n",
        "---\n",
        "\n",
        "<img src=\"https://i.pinimg.com/564x/4c/fe/ef/4cfeef34af09973211f584e8307b433c.jpg\" alt=\"`Impossible mission\" style=\"height: 300px; width:500px;\"/>\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "‚ùì **Your mission, should you choose to accept it:** ‚ùì\n",
        "- üí™ Beat the best boosted-tree üí™ \n",
        "\n",
        "    - Your responsibilities are:\n",
        "        - to build the ***best neural network architecture*** possible,\n",
        "        - and to control the number of epochs to ***avoid overfitting***."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7qPpbuDBILx"
      },
      "source": [
        "### (2.1) Predicting the houses' prices using a Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVTkq19eBILx"
      },
      "source": [
        "‚ùì **Preliminary Question: Initializing a Neural Network** ‚ùì\n",
        "\n",
        "Create a function `initialize_model` which initializes a Dense Neural network:\n",
        "- You are responsible for designing the architecture (number of layers, number of neurons)\n",
        "- The function should also compile the model with the following parameters:\n",
        "    - ***optimizer = \"adam\"***\n",
        "    - ***loss = \"msle\"*** (_Optimizing directly for the Squared Log Error!_)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "id": "o5RLX8EIBILx"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential, layers\n",
        "def initialize_model():\n",
        "    model = Sequential()\n",
        "    model.add(layers.Dense(10, activation='relu', input_dim=158))\n",
        "    model.add(layers.Dense(500, activation='relu'))\n",
        "    model.add(layers.Dense(500, activation='relu'))\n",
        "    model.add(layers.Dense(1, activation='linear'))\n",
        "    model.compile(loss='msle', # different from binary_crossentropy because we have multiple classes\n",
        "                  optimizer='adam') \n",
        "\n",
        "    return model \n",
        "\n",
        "\n",
        "model = initialize_model()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_transformed, y_train, batch_size=32, epochs=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dACRh6BVFmv_",
        "outputId": "a14fa0c4-5bf6-4eda-ae21-3bb8c71e4857"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "32/32 [==============================] - 1s 8ms/step - loss: 94.7217\n",
            "Epoch 2/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 45.5492\n",
            "Epoch 3/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 27.3249\n",
            "Epoch 4/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 18.3619\n",
            "Epoch 5/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 13.2703\n",
            "Epoch 6/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 9.9996\n",
            "Epoch 7/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 7.7305\n",
            "Epoch 8/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 6.0716\n",
            "Epoch 9/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 4.8393\n",
            "Epoch 10/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.9051\n",
            "Epoch 11/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 3.1814\n",
            "Epoch 12/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.6100\n",
            "Epoch 13/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 2.1560\n",
            "Epoch 14/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.7922\n",
            "Epoch 15/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 1.4983\n",
            "Epoch 16/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.2584\n",
            "Epoch 17/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.0621\n",
            "Epoch 18/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.9001\n",
            "Epoch 19/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.7656\n",
            "Epoch 20/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.6531\n",
            "Epoch 21/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.5589\n",
            "Epoch 22/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.4803\n",
            "Epoch 23/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.4144\n",
            "Epoch 24/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.3595\n",
            "Epoch 25/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.3133\n",
            "Epoch 26/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2752\n",
            "Epoch 27/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.2435\n",
            "Epoch 28/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.2170\n",
            "Epoch 29/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1950\n",
            "Epoch 30/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1767\n",
            "Epoch 31/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1610\n",
            "Epoch 32/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1478\n",
            "Epoch 33/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1368\n",
            "Epoch 34/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1280\n",
            "Epoch 35/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1209\n",
            "Epoch 36/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.1152\n",
            "Epoch 37/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1107\n",
            "Epoch 38/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1071\n",
            "Epoch 39/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1043\n",
            "Epoch 40/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1021\n",
            "Epoch 41/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1003\n",
            "Epoch 42/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0989\n",
            "Epoch 43/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0978\n",
            "Epoch 44/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0969\n",
            "Epoch 45/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0961\n",
            "Epoch 46/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0955\n",
            "Epoch 47/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0949\n",
            "Epoch 48/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0944\n",
            "Epoch 49/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0940\n",
            "Epoch 50/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0936\n",
            "Epoch 51/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0932\n",
            "Epoch 52/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0928\n",
            "Epoch 53/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0924\n",
            "Epoch 54/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0921\n",
            "Epoch 55/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0917\n",
            "Epoch 56/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0914\n",
            "Epoch 57/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0910\n",
            "Epoch 58/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0906\n",
            "Epoch 59/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0903\n",
            "Epoch 60/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0899\n",
            "Epoch 61/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0895\n",
            "Epoch 62/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0891\n",
            "Epoch 63/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0888\n",
            "Epoch 64/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0884\n",
            "Epoch 65/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0880\n",
            "Epoch 66/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0876\n",
            "Epoch 67/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0872\n",
            "Epoch 68/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0868\n",
            "Epoch 69/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0864\n",
            "Epoch 70/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0859\n",
            "Epoch 71/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0855\n",
            "Epoch 72/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0851\n",
            "Epoch 73/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0847\n",
            "Epoch 74/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0843\n",
            "Epoch 75/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0838\n",
            "Epoch 76/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0834\n",
            "Epoch 77/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0830\n",
            "Epoch 78/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0825\n",
            "Epoch 79/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0821\n",
            "Epoch 80/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0816\n",
            "Epoch 81/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0812\n",
            "Epoch 82/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0807\n",
            "Epoch 83/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0802\n",
            "Epoch 84/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0798\n",
            "Epoch 85/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0793\n",
            "Epoch 86/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0789\n",
            "Epoch 87/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0783\n",
            "Epoch 88/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0779\n",
            "Epoch 89/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0774\n",
            "Epoch 90/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0769\n",
            "Epoch 91/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0764\n",
            "Epoch 92/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0759\n",
            "Epoch 93/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0754\n",
            "Epoch 94/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0749\n",
            "Epoch 95/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0744\n",
            "Epoch 96/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0739\n",
            "Epoch 97/500\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0734\n",
            "Epoch 98/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0729\n",
            "Epoch 99/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0724\n",
            "Epoch 100/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0719\n",
            "Epoch 101/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0714\n",
            "Epoch 102/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0709\n",
            "Epoch 103/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0703\n",
            "Epoch 104/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0698\n",
            "Epoch 105/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0693\n",
            "Epoch 106/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0688\n",
            "Epoch 107/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0682\n",
            "Epoch 108/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0677\n",
            "Epoch 109/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0672\n",
            "Epoch 110/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0667\n",
            "Epoch 111/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0661\n",
            "Epoch 112/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0656\n",
            "Epoch 113/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0651\n",
            "Epoch 114/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0645\n",
            "Epoch 115/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0640\n",
            "Epoch 116/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0635\n",
            "Epoch 117/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0629\n",
            "Epoch 118/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0624\n",
            "Epoch 119/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0619\n",
            "Epoch 120/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0613\n",
            "Epoch 121/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0608\n",
            "Epoch 122/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0603\n",
            "Epoch 123/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0598\n",
            "Epoch 124/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0592\n",
            "Epoch 125/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0587\n",
            "Epoch 126/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0582\n",
            "Epoch 127/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0576\n",
            "Epoch 128/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0571\n",
            "Epoch 129/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0566\n",
            "Epoch 130/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0560\n",
            "Epoch 131/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0555\n",
            "Epoch 132/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0550\n",
            "Epoch 133/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0545\n",
            "Epoch 134/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0540\n",
            "Epoch 135/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0535\n",
            "Epoch 136/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0530\n",
            "Epoch 137/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0525\n",
            "Epoch 138/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0520\n",
            "Epoch 139/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0515\n",
            "Epoch 140/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0510\n",
            "Epoch 141/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0505\n",
            "Epoch 142/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0500\n",
            "Epoch 143/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0495\n",
            "Epoch 144/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0490\n",
            "Epoch 145/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0485\n",
            "Epoch 146/500\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0481\n",
            "Epoch 147/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0476\n",
            "Epoch 148/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0471\n",
            "Epoch 149/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0467\n",
            "Epoch 150/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0462\n",
            "Epoch 151/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0458\n",
            "Epoch 152/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0453\n",
            "Epoch 153/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0449\n",
            "Epoch 154/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0444\n",
            "Epoch 155/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0440\n",
            "Epoch 156/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0436\n",
            "Epoch 157/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0432\n",
            "Epoch 158/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0427\n",
            "Epoch 159/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0423\n",
            "Epoch 160/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0419\n",
            "Epoch 161/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0416\n",
            "Epoch 162/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0411\n",
            "Epoch 163/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0408\n",
            "Epoch 164/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0404\n",
            "Epoch 165/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0400\n",
            "Epoch 166/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0396\n",
            "Epoch 167/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0392\n",
            "Epoch 168/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0388\n",
            "Epoch 169/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0385\n",
            "Epoch 170/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0381\n",
            "Epoch 171/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0378\n",
            "Epoch 172/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0374\n",
            "Epoch 173/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0371\n",
            "Epoch 174/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0367\n",
            "Epoch 175/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0364\n",
            "Epoch 176/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0360\n",
            "Epoch 177/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0357\n",
            "Epoch 178/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0354\n",
            "Epoch 179/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0351\n",
            "Epoch 180/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0347\n",
            "Epoch 181/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0344\n",
            "Epoch 182/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0341\n",
            "Epoch 183/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0338\n",
            "Epoch 184/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0335\n",
            "Epoch 185/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0332\n",
            "Epoch 186/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0329\n",
            "Epoch 187/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0326\n",
            "Epoch 188/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0323\n",
            "Epoch 189/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0320\n",
            "Epoch 190/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0318\n",
            "Epoch 191/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0315\n",
            "Epoch 192/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0312\n",
            "Epoch 193/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0310\n",
            "Epoch 194/500\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0307\n",
            "Epoch 195/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0304\n",
            "Epoch 196/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0302\n",
            "Epoch 197/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0299\n",
            "Epoch 198/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0296\n",
            "Epoch 199/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0294\n",
            "Epoch 200/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0292\n",
            "Epoch 201/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0289\n",
            "Epoch 202/500\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0287\n",
            "Epoch 203/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0285\n",
            "Epoch 204/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0282\n",
            "Epoch 205/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0280\n",
            "Epoch 206/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0278\n",
            "Epoch 207/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0276\n",
            "Epoch 208/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0273\n",
            "Epoch 209/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0271\n",
            "Epoch 210/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0269\n",
            "Epoch 211/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0267\n",
            "Epoch 212/500\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0265\n",
            "Epoch 213/500\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0263\n",
            "Epoch 214/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0261\n",
            "Epoch 215/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0259\n",
            "Epoch 216/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0257\n",
            "Epoch 217/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0255\n",
            "Epoch 218/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0253\n",
            "Epoch 219/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0252\n",
            "Epoch 220/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0250\n",
            "Epoch 221/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0248\n",
            "Epoch 222/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0247\n",
            "Epoch 223/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0245\n",
            "Epoch 224/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0243\n",
            "Epoch 225/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0241\n",
            "Epoch 226/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0240\n",
            "Epoch 227/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0238\n",
            "Epoch 228/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0237\n",
            "Epoch 229/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0235\n",
            "Epoch 230/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0234\n",
            "Epoch 231/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0232\n",
            "Epoch 232/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0231\n",
            "Epoch 233/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0230\n",
            "Epoch 234/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0228\n",
            "Epoch 235/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0227\n",
            "Epoch 236/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0225\n",
            "Epoch 237/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0224\n",
            "Epoch 238/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0223\n",
            "Epoch 239/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0221\n",
            "Epoch 240/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0220\n",
            "Epoch 241/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0219\n",
            "Epoch 242/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0218\n",
            "Epoch 243/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0216\n",
            "Epoch 244/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0216\n",
            "Epoch 245/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0214\n",
            "Epoch 246/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0213\n",
            "Epoch 247/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0211\n",
            "Epoch 248/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0211\n",
            "Epoch 249/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0210\n",
            "Epoch 250/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0208\n",
            "Epoch 251/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0208\n",
            "Epoch 252/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0206\n",
            "Epoch 253/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0205\n",
            "Epoch 254/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0204\n",
            "Epoch 255/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0203\n",
            "Epoch 256/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0202\n",
            "Epoch 257/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0201\n",
            "Epoch 258/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0200\n",
            "Epoch 259/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0199\n",
            "Epoch 260/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0198\n",
            "Epoch 261/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0197\n",
            "Epoch 262/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0196\n",
            "Epoch 263/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0195\n",
            "Epoch 264/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0194\n",
            "Epoch 265/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0194\n",
            "Epoch 266/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0192\n",
            "Epoch 267/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0192\n",
            "Epoch 268/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0191\n",
            "Epoch 269/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0189\n",
            "Epoch 270/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0189\n",
            "Epoch 271/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0188\n",
            "Epoch 272/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0187\n",
            "Epoch 273/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0186\n",
            "Epoch 274/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0185\n",
            "Epoch 275/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0184\n",
            "Epoch 276/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0184\n",
            "Epoch 277/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0183\n",
            "Epoch 278/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0182\n",
            "Epoch 279/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0182\n",
            "Epoch 280/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0181\n",
            "Epoch 281/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0180\n",
            "Epoch 282/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0179\n",
            "Epoch 283/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0179\n",
            "Epoch 284/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0177\n",
            "Epoch 285/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0177\n",
            "Epoch 286/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0176\n",
            "Epoch 287/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0176\n",
            "Epoch 288/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0175\n",
            "Epoch 289/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0174\n",
            "Epoch 290/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0174\n",
            "Epoch 291/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0173\n",
            "Epoch 292/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0172\n",
            "Epoch 293/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0171\n",
            "Epoch 294/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0170\n",
            "Epoch 295/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0170\n",
            "Epoch 296/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0169\n",
            "Epoch 297/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0168\n",
            "Epoch 298/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0167\n",
            "Epoch 299/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0167\n",
            "Epoch 300/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0167\n",
            "Epoch 301/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0167\n",
            "Epoch 302/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0165\n",
            "Epoch 303/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0164\n",
            "Epoch 304/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0165\n",
            "Epoch 305/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0164\n",
            "Epoch 306/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0163\n",
            "Epoch 307/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0162\n",
            "Epoch 308/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0163\n",
            "Epoch 309/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0161\n",
            "Epoch 310/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0161\n",
            "Epoch 311/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0160\n",
            "Epoch 312/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0160\n",
            "Epoch 313/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0160\n",
            "Epoch 314/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0159\n",
            "Epoch 315/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0158\n",
            "Epoch 316/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0157\n",
            "Epoch 317/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0157\n",
            "Epoch 318/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0157\n",
            "Epoch 319/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0156\n",
            "Epoch 320/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0156\n",
            "Epoch 321/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0155\n",
            "Epoch 322/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0155\n",
            "Epoch 323/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0155\n",
            "Epoch 324/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0154\n",
            "Epoch 325/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0153\n",
            "Epoch 326/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0153\n",
            "Epoch 327/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0153\n",
            "Epoch 328/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0152\n",
            "Epoch 329/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0151\n",
            "Epoch 330/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0151\n",
            "Epoch 331/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0152\n",
            "Epoch 332/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0151\n",
            "Epoch 333/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0150\n",
            "Epoch 334/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0150\n",
            "Epoch 335/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0150\n",
            "Epoch 336/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0149\n",
            "Epoch 337/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0149\n",
            "Epoch 338/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0149\n",
            "Epoch 339/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0149\n",
            "Epoch 340/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0148\n",
            "Epoch 341/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0147\n",
            "Epoch 342/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0147\n",
            "Epoch 343/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0147\n",
            "Epoch 344/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0147\n",
            "Epoch 345/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0147\n",
            "Epoch 346/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0146\n",
            "Epoch 347/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0145\n",
            "Epoch 348/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0146\n",
            "Epoch 349/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0145\n",
            "Epoch 350/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0145\n",
            "Epoch 351/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0144\n",
            "Epoch 352/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0143\n",
            "Epoch 353/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0144\n",
            "Epoch 354/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0144\n",
            "Epoch 355/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0144\n",
            "Epoch 356/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0143\n",
            "Epoch 357/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0143\n",
            "Epoch 358/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0143\n",
            "Epoch 359/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0142\n",
            "Epoch 360/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0142\n",
            "Epoch 361/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0142\n",
            "Epoch 362/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0143\n",
            "Epoch 363/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0141\n",
            "Epoch 364/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0141\n",
            "Epoch 365/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0141\n",
            "Epoch 366/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0141\n",
            "Epoch 367/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0140\n",
            "Epoch 368/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0140\n",
            "Epoch 369/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0140\n",
            "Epoch 370/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0140\n",
            "Epoch 371/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0142\n",
            "Epoch 372/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0140\n",
            "Epoch 373/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0140\n",
            "Epoch 374/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0139\n",
            "Epoch 375/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0138\n",
            "Epoch 376/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0139\n",
            "Epoch 377/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0139\n",
            "Epoch 378/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0138\n",
            "Epoch 379/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0139\n",
            "Epoch 380/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0138\n",
            "Epoch 381/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0138\n",
            "Epoch 382/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0139\n",
            "Epoch 383/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0138\n",
            "Epoch 384/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0138\n",
            "Epoch 385/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0139\n",
            "Epoch 386/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0138\n",
            "Epoch 387/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0137\n",
            "Epoch 388/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0137\n",
            "Epoch 389/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0137\n",
            "Epoch 390/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0136\n",
            "Epoch 391/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0136\n",
            "Epoch 392/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0137\n",
            "Epoch 393/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0136\n",
            "Epoch 394/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0136\n",
            "Epoch 395/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0139\n",
            "Epoch 396/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0136\n",
            "Epoch 397/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0135\n",
            "Epoch 398/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0136\n",
            "Epoch 399/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0135\n",
            "Epoch 400/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0135\n",
            "Epoch 401/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0135\n",
            "Epoch 402/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0135\n",
            "Epoch 403/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0136\n",
            "Epoch 404/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0134\n",
            "Epoch 405/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0135\n",
            "Epoch 406/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0135\n",
            "Epoch 407/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0134\n",
            "Epoch 408/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0134\n",
            "Epoch 409/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0133\n",
            "Epoch 410/500\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0133\n",
            "Epoch 411/500\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.0134\n",
            "Epoch 412/500\n",
            "32/32 [==============================] - 0s 16ms/step - loss: 0.0133\n",
            "Epoch 413/500\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0133\n",
            "Epoch 414/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0134\n",
            "Epoch 415/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0134\n",
            "Epoch 416/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0134\n",
            "Epoch 417/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0133\n",
            "Epoch 418/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0133\n",
            "Epoch 419/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0133\n",
            "Epoch 420/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0133\n",
            "Epoch 421/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0135\n",
            "Epoch 422/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0132\n",
            "Epoch 423/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0132\n",
            "Epoch 424/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0133\n",
            "Epoch 425/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0132\n",
            "Epoch 426/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0131\n",
            "Epoch 427/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0132\n",
            "Epoch 428/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0133\n",
            "Epoch 429/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0131\n",
            "Epoch 430/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0131\n",
            "Epoch 431/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0131\n",
            "Epoch 432/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0131\n",
            "Epoch 433/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0131\n",
            "Epoch 434/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0131\n",
            "Epoch 435/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0132\n",
            "Epoch 436/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0132\n",
            "Epoch 437/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0130\n",
            "Epoch 438/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0131\n",
            "Epoch 439/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0131\n",
            "Epoch 440/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0132\n",
            "Epoch 441/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0131\n",
            "Epoch 442/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0131\n",
            "Epoch 443/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0130\n",
            "Epoch 444/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0130\n",
            "Epoch 445/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0130\n",
            "Epoch 446/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0130\n",
            "Epoch 447/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0130\n",
            "Epoch 448/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0129\n",
            "Epoch 449/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0129\n",
            "Epoch 450/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0129\n",
            "Epoch 451/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0129\n",
            "Epoch 452/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0131\n",
            "Epoch 453/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0130\n",
            "Epoch 454/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0130\n",
            "Epoch 455/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0132\n",
            "Epoch 456/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0131\n",
            "Epoch 457/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0129\n",
            "Epoch 458/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0130\n",
            "Epoch 459/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0130\n",
            "Epoch 460/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0131\n",
            "Epoch 461/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0129\n",
            "Epoch 462/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0128\n",
            "Epoch 463/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0129\n",
            "Epoch 464/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0129\n",
            "Epoch 465/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0134\n",
            "Epoch 466/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0129\n",
            "Epoch 467/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0127\n",
            "Epoch 468/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0130\n",
            "Epoch 469/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0128\n",
            "Epoch 470/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0128\n",
            "Epoch 471/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0128\n",
            "Epoch 472/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0127\n",
            "Epoch 473/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0130\n",
            "Epoch 474/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0128\n",
            "Epoch 475/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0129\n",
            "Epoch 476/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0129\n",
            "Epoch 477/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0128\n",
            "Epoch 478/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0127\n",
            "Epoch 479/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0128\n",
            "Epoch 480/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0128\n",
            "Epoch 481/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0128\n",
            "Epoch 482/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0127\n",
            "Epoch 483/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0128\n",
            "Epoch 484/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0127\n",
            "Epoch 485/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0129\n",
            "Epoch 486/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0128\n",
            "Epoch 487/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0129\n",
            "Epoch 488/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0127\n",
            "Epoch 489/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0126\n",
            "Epoch 490/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0127\n",
            "Epoch 491/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0127\n",
            "Epoch 492/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0127\n",
            "Epoch 493/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0127\n",
            "Epoch 494/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0129\n",
            "Epoch 495/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0126\n",
            "Epoch 496/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0126\n",
            "Epoch 497/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0126\n",
            "Epoch 498/500\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0129\n",
            "Epoch 499/500\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0127\n",
            "Epoch 500/500\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gZwEaZmBILx"
      },
      "source": [
        "‚ùì **Questions/Guidance** ‚ùì\n",
        "\n",
        "1. Initialize a Neural Network\n",
        "2. Train it\n",
        "3. Evaluate its performance\n",
        "4. Is the model overfitting the dataset? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zL8jgEkTBILy",
        "outputId": "31cb8c4e-d0cc-44cf-c37f-215b79ece9b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0232\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15239946251413664"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "model.evaluate(X_test_transformed, y_test)**0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OA49Vn3BILy"
      },
      "source": [
        "üéÅ We coded a `plot_history` function that you can use to detect overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "V8v6CxhsBILy"
      },
      "outputs": [],
      "source": [
        "def plot_history(history):\n",
        "    plt.plot(np.sqrt(history.history['loss']))\n",
        "    plt.plot(np.sqrt(history.history['val_loss']))\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('RMSLE')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Val'], loc='best')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "AM_bHfeiBILy",
        "outputId": "67a1f680-22cc-462a-f9c5-15d74d9bda43"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-a8489d1127d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-76-1157ba85f4b9>\u001b[0m in \u001b[0;36mplot_history\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RMSLE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nR6b8E1BILy"
      },
      "source": [
        "### (2.2) Challenging yourself"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc9xbgPqBILy"
      },
      "source": [
        "‚ùì **Questions to challenge yourself:** ‚ùì\n",
        "- Are you satisfied with your score?\n",
        "- Before publishing it, ask yourself whether you could really trust it or not?\n",
        "- Have you cross-validated your neural network? \n",
        "    - Feel free to cross-validate it manually with a *for loop* in Python to make sure that your results are robust against the randomness of a _train-val split_ before before submitting to Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mloNe00xBILy"
      },
      "source": [
        "### (2.3) (Bonus) Using all your CPU cores to run Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRNSvoD3BILy"
      },
      "source": [
        "üî• **BONUS** üî• **Multiprocessing computing using [dask](https://docs.dask.org/en/latest/delayed.html)** and **all your CPU cores**:\n",
        "\n",
        "_(to mimic SkLearn's `n_jobs=-1`)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "UZAruSqIBILz"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet dask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "nuEeXW2eBILz",
        "outputId": "90115d68-e618-4542-be8f-5adb45d1ea2d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-68e7f2f4ba21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m results = delayed([f(X_preproc, y, train_index, val_index) for (train_index, val_index) in kf.split(X_preproc)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'evaluate_model' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from dask import delayed\n",
        "\n",
        "cv = 5\n",
        "kf = KFold(n_splits = cv, shuffle = True)\n",
        "f = delayed(evaluate_model)\n",
        "\n",
        "results = delayed([f(X_preproc, y, train_index, val_index) for (train_index, val_index) in kf.split(X_preproc)\n",
        "                   ]).compute(\n",
        "                       scheduler='processes', num_workers=8)\n",
        "\n",
        "pd.concat(results, axis=0).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W38s3xuwBILz"
      },
      "source": [
        "## (3) üèÖFINAL SUBMISSION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw86m2KsBILz"
      },
      "source": [
        "ü¶Ñ Predict the ***prices of the houses in your test set*** and submit your results to Kaggle! \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "6uWFF2fGBILz"
      },
      "outputs": [],
      "source": [
        "X_test = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/houses_test_raw.csv\")\n",
        "X_test_preproc = preproc.transform(X_test)\n",
        "#ALREADY DONE ABOVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "id": "wKgChdTiBILz"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rofzuxk_BILz"
      },
      "source": [
        "üíæ Save your predictions in a Dataframe called `results` with the format required by Kaggle so that when you export it to a `.csv`, Kaggle can read it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "id": "vJsB60UMBILz"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_-ufg34BILz"
      },
      "source": [
        "üì§  Export your results using Kaggle's submission format and submit it online!\n",
        "\n",
        "_(Uncomment the last cell of this notebook)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aibi5-06BILz"
      },
      "outputs": [],
      "source": [
        "# results.to_csv(\"submission_final.csv\", header = True, index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQoaf67kBILz"
      },
      "source": [
        "---\n",
        "\n",
        "üèÅ Congratulations!\n",
        "\n",
        "üíæ Don't forget to `git add/commit/push` your notebook...\n",
        "\n",
        "üöÄ ... it's time for the Recap!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "houses_kaggle_competition_bis.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}